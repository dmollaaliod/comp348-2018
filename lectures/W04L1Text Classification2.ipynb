{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gender Classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/names.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"names\")\n",
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = names.words('male.txt')\n",
    "f = names.words('female.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(1234) # Set the seed to facilitate replicability\n",
    "names = ([(name, 'male') for name in m] +\n",
    "         [(name, 'female') for name in f])\n",
    "random.shuffle(names)\n",
    "train_names = names[1500:]\n",
    "devtest_names = names[500:1500]\n",
    "test_names = names[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def one_hot_character(c):\n",
    "  alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "  result = [0]*len(alphabet)\n",
    "  try:\n",
    "     result[alphabet.index(c.lower())] = 1\n",
    "  except:\n",
    "     print(\"Warning: unable to encode character '%c'\" % c)\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_character('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_character('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    last = one_hot_character(word[-1])\n",
    "    secondlast = one_hot_character(word[-2])\n",
    "    return secondlast + last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features('Mary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: unable to encode character ' '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "train_set = [(gender_features(n), g) for n, g in train_names]\n",
    "devtest_set = [(gender_features(n), g) for n, g in devtest_names]\n",
    "test_set = [(gender_features(n), g) for n, g in test_names]\n",
    "train_X,train_y = zip(*train_set)\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "devtest_X,devtest_y = zip(*devtest_set)\n",
    "devtest_predictions = classifier.predict(devtest_X)\n",
    "accuracy_score(devtest_y, devtest_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-Learn provides LabelBinarizer to encode labels using one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit([c for c in alphabet])\n",
    "def one_hot_character2(c):\n",
    "    return list(lb.transform([c])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_character2('c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gender_features2(word):\n",
    "    last = one_hot_character2(word[-1])\n",
    "    secondlast = one_hot_character2(word[-2])\n",
    "    return secondlast + last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_features2(\"Mary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set2 = [(gender_features2(n), g) for n, g in train_names]\n",
    "devtest_set2 = [(gender_features2(n), g) for n, g in devtest_names]\n",
    "test_set2 = [(gender_features2(n), g) for n, g in test_names]\n",
    "train_X2,train_y2 = zip(*train_set2)\n",
    "classifier2 = MultinomialNB()\n",
    "classifier2.fit(train_X2, train_y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.752"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devtest_X2,devtest_y2 = zip(*devtest_set2)\n",
    "devtest_predictions2 = classifier.predict(devtest_X2)\n",
    "accuracy_score(devtest_y2, devtest_predictions2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['neg', 'pos']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"movie_reviews\")\n",
    "from nltk.corpus import movie_reviews\n",
    "movie_reviews.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative reviews: 1000\n",
      "Number of positive reviews: 1000\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of negative reviews:\", len(movie_reviews.fileids('neg')))\n",
    "print(\"Number of positive reviews:\", len(movie_reviews.fileids('pos')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code partitions the movie review corpus into a training and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "documents_words = [(list(movie_reviews.words(fileid)), category)\n",
    "                   for category in movie_reviews.categories()\n",
    "                   for fileid in movie_reviews.fileids(category)]\n",
    "random.seed(1234)\n",
    "random.shuffle(documents_words)\n",
    "threshold1 = int(len(documents_words)*.6)\n",
    "threshold2 = int(len(documents_words)*.8)\n",
    "train_words = documents_words[:threshold1]\n",
    "devtest_words = documents_words[threshold1:threshold2]\n",
    "test_words = documents_words[threshold2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code finds the 2000 most frequent non-stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "nltk.download(\"stopwords\")\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "c = collections.Counter([w.lower() for (words, category) in train_words \n",
    "                                   for w in words if w.lower() not in stop])\n",
    "top2000words = [w for (w, count) in c.most_common(2000)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code implements one-hot encoding with the 2000 most frequent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def document_features(words):\n",
    "    \"Return the document features for an NLTK classifier\"\n",
    "    words_lower = [w.lower() for w in words]\n",
    "    result = dict()\n",
    "    for w in top2000words:\n",
    "        result['has(%s)' % w] = (w in words_lower)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here we train an NLTK Naive Bayes classifier using the training set, and evaluate the system using the devtest set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = [(document_features(x), y) for (x, y) in train_words]\n",
    "devtest_features = [(document_features(x), y) for (x, y) in devtest_words]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7775"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, devtest_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8816666666666667"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, train_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see the difference in accuracy between the test set and the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code defines a second feature extractor on the same list of 2000 words, and which is suitable for sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_features(words):\n",
    "    \"Return a vector of features for sklearn\"\n",
    "    words_lower = [w.lower() for w in words]\n",
    "    result = []\n",
    "    for w in top2000words:\n",
    "        if w in words_lower:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the code that generates the vectors, trains a Multinomial Naive Bayes classifier, and evaluates the result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_vectors = [vector_features(x) for (x, y) in train_words]\n",
    "train_labels = [y for (x, y) in train_words]\n",
    "devtest_vectors = [vector_features(x) for (x, y) in devtest_words]\n",
    "devtest_labels = [y for (x, y) in devtest_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "sklearn_classifier = MultinomialNB()\n",
    "sklearn_classifier.fit(train_vectors, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83999999999999997"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sklearn_classifier.predict(devtest_vectors)\n",
    "accuracy_score(devtest_labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92000000000000004"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sklearn_classifier.predict(train_vectors)\n",
    "accuracy_score(train_labels, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tf-idf as features in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "documents_raw = [(movie_reviews.raw(fileid), category)\n",
    "                 for category in movie_reviews.categories()\n",
    "                 for fileid in movie_reviews.fileids(category)]\n",
    "random.seed(1234)\n",
    "random.shuffle(documents_raw)\n",
    "threshold1 = int(len(documents_raw)*.6)\n",
    "threshold2 = int(len(documents_raw)*.8)\n",
    "train_raw = documents_raw[:threshold1]\n",
    "train_labels_raw = [y for x, y in train_raw]\n",
    "devtest_raw = documents_raw[threshold1:threshold2]\n",
    "devtest_labels_raw = [y for x, y in devtest_raw]\n",
    "test_raw = documents_raw[threshold2:]\n",
    "test_labels_raw = [y for x, y in test_raw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "train_features = tfidf.fit_transform([x for x, y in train_raw])\n",
    "\n",
    "sklearn_classifier2 = MultinomialNB()\n",
    "sklearn_classifier2.fit(train_features, train_labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81000000000000005"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "devtest_features = tfidf.transform([x for x, y in devtest_raw])\n",
    "predictions = sklearn_classifier2.predict(devtest_features)\n",
    "accuracy_score(devtest_labels_raw, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98083333333333333"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = sklearn_classifier2.predict(train_features)\n",
    "accuracy_score(train_labels_raw, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And below is the code that uses Support Vector Machines (SVM) instead. You can see that the interface is the same. SVMs typically give very good results, especially when the amount of training data is large enough (in this case it wasn't)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "sklearn_classifier3 = SVC()\n",
    "sklearn_classifier3.fit(train_features, train_labels_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.51500000000000001"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3 = sklearn_classifier3.predict(devtest_features)\n",
    "accuracy_score(devtest_labels_raw, predictions3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50083333333333335"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions3 = sklearn_classifier3.predict(train_features)\n",
    "accuracy_score(train_labels_raw, predictions3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-fold Cross Validation using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79338843,  0.80833333,  0.76666667,  0.79166667,  0.80833333,\n",
       "        0.79166667,  0.825     ,  0.83333333,  0.79166667,  0.80672269])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "crossval_classifier = MultinomialNB()\n",
    "scores = cross_val_score(crossval_classifier, train_features, train_labels_raw, cv=10, scoring=\"accuracy\")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of accuracy: 0.801677778549\n",
      "Standard deviation of accuracy: 0.018042179595\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean of accuracy:\", scores.mean())\n",
    "print(\"Standard deviation of accuracy:\", scores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Accuracy: 0.683\n",
      "Fold 1:\n",
      "Accuracy: 0.792\n",
      "Fold 2:\n",
      "Accuracy: 0.817\n",
      "Fold 3:\n",
      "Accuracy: 0.717\n",
      "Fold 4:\n",
      "Accuracy: 0.833\n",
      "Fold 5:\n",
      "Accuracy: 0.750\n",
      "Fold 6:\n",
      "Accuracy: 0.833\n",
      "Fold 7:\n",
      "Accuracy: 0.850\n",
      "Fold 8:\n",
      "Accuracy: 0.808\n",
      "Fold 9:\n",
      "Accuracy: 0.800\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "fold = 0\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=1234)\n",
    "train_labels_array = np.array(train_labels_raw)\n",
    "for kv_train, kv_test in kf.split(train_raw):\n",
    "    # kv_train and kv_test are indices of array dev_vectors\n",
    "    print(\"Fold %i:\" % fold)\n",
    "    fold += 1\n",
    "    cv_classifier = MultinomialNB()\n",
    "    cv_classifier.fit(train_features[kv_train], train_labels_array[kv_train])\n",
    "    test_predictions = cv_classifier.predict(train_features[kv_test])\n",
    "    test_accuracy = accuracy_score(train_labels_array[kv_test], test_predictions)\n",
    "    print(\"Accuracy: %.3f\" % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code splits the Brown corpus into a training and test set. **Note that now we cannot shuffle the sentences since we will need information from text from previous and following sentences.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"brown\")\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents = brown.sents(categories='news')\n",
    "size = int(len(sents)*0.1)\n",
    "train_sents, test_sents = sents[size:], sents[:size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code extracts the boundary information of tokenised sentences. This can be used for our annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_boundaries(sents):\n",
    "    \"\"\"Return the tokens and the sentence boundary positions\"\"\"\n",
    "    tokens = []\n",
    "    boundaries = []\n",
    "    offset = 0\n",
    "    for sent in sents:\n",
    "        tokens.extend(sent)\n",
    "        offset += len(sent)\n",
    "        boundaries.append(offset-1)\n",
    "    return tokens, boundaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_tokens, train_boundaries = extract_boundaries(train_sents)\n",
    "test_tokens, test_boundaries = extract_boundaries(test_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['He',\n",
       " 'assured',\n",
       " 'Mr.',\n",
       " 'Martinelli',\n",
       " 'and',\n",
       " 'the',\n",
       " 'council',\n",
       " 'that',\n",
       " 'he',\n",
       " 'would',\n",
       " 'study',\n",
       " 'the',\n",
       " 'correct',\n",
       " 'method',\n",
       " 'and',\n",
       " 'report',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'council',\n",
       " 'as',\n",
       " 'soon',\n",
       " 'as',\n",
       " 'possible',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'Martinelli',\n",
       " 'said',\n",
       " 'yesterday',\n",
       " 'that',\n",
       " 'the',\n",
       " 'Citizens',\n",
       " 'Group',\n",
       " 'of',\n",
       " 'Johnston',\n",
       " 'will',\n",
       " 'meet',\n",
       " 'again',\n",
       " 'July',\n",
       " '24',\n",
       " 'to',\n",
       " 'plan',\n",
       " 'further',\n",
       " 'strategy',\n",
       " 'in',\n",
       " 'the',\n",
       " 'charter',\n",
       " 'movement',\n",
       " '.',\n",
       " 'He']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[24, 48, 77, 96, 115, 149, 181, 202, 239, 252]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_boundaries[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['soon', 'as', 'possible', '.', 'Mr.']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens[21:26]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define context-based features for all tokens that are candidates to sentence endings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segmenter_features(tokens, i):\n",
    "    \"\"\"Return the features of token[i]\"\"\"\n",
    "    return {'next-word-capitalized': \n",
    "                  tokens[i+1][0].isupper(),\n",
    "            'prev-word': tokens[i-1].lower(),\n",
    "            'punct': tokens[i],\n",
    "            'prev-word-is-one-char': \n",
    "                  len(tokens[i-1]) == 1}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the tokens, boundaries, and feature extractor, we can prepare the training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "candidates = '.?!'\n",
    "train_features = [(segmenter_features(train_tokens, i), \n",
    "                   (i in train_boundaries))\n",
    "                 for i in range(1, len(train_tokens)-1)\n",
    "                 if train_tokens[i] in candidates]\n",
    "test_features = [(segmenter_features(test_tokens, i), \n",
    "                  (i in test_boundaries))\n",
    "                 for i in range(1, len(test_tokens)-1)\n",
    "                 if test_tokens[i] in candidates]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'next-word-capitalized': True,\n",
       "   'prev-word': 'possible',\n",
       "   'prev-word-is-one-char': False,\n",
       "   'punct': '.'},\n",
       "  True),\n",
       " ({'next-word-capitalized': True,\n",
       "   'prev-word': 'movement',\n",
       "   'prev-word-is-one-char': False,\n",
       "   'punct': '.'},\n",
       "  True),\n",
       " ({'next-word-capitalized': False,\n",
       "   'prev-word': 'comes',\n",
       "   'prev-word-is-one-char': False,\n",
       "   'punct': '.'},\n",
       "  True)]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3749, 407)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_features), len(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a classifier that can be used for sentence segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segmenter = nltk.NaiveBayesClassifier.train(train_features)\n",
    "nltk.classify.accuracy(segmenter, test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks impressive! but let's check what would happen if we introduced a majority baseline classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 62, True: 3687})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train_counter = Counter([f[1] for f in train_features])\n",
    "train_counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since most training samples are labelled as `True,` the majority baseline is a classifier that always outputs `True`. In that case, accuracy in the test set is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({False: 2, True: 405})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_counter = Counter([f[1] for f in test_features])\n",
    "test_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995085995085995"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "405/407"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the majority baseline was not that impressive after all. The finished segmenter that uses the trained classifier is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def segment_sentences(tokens):\n",
    "    \"\"\"Segment a list of tokens\"\"\"\n",
    "    start = 0\n",
    "    sents = []\n",
    "    for i, token in enumerate(tokens):\n",
    "        if token in candidates and \\\n",
    "           segmenter.classify(segmenter_features(tokens, i)) == True:\n",
    "               sents.append(tokens[start:i+1])\n",
    "               start = i+1\n",
    "    if start < len(tokens):\n",
    "        sents.append(tokens[start:])\n",
    "    return sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['This', 'is', 'a', 'sentence', '.'], ['This', 'is', 'another', 'one']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment_sentences([\"This\", \"is\", \"a\", \"sentence\", \".\", \"This\", \n",
    "                    \"is\", \"another\", \"one\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Reuters-21578 Corpus\n",
    "The Reuters-21578 is an example of a corpus for multi-label text classification. Each news item in the corpus has been annotated with the labels of all the topics for which the news item is relevant. This means that one news item could have several labels, or even none at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"reuters\")\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['acq',\n",
       " 'alum',\n",
       " 'barley',\n",
       " 'bop',\n",
       " 'carcass',\n",
       " 'castor-oil',\n",
       " 'cocoa',\n",
       " 'coconut',\n",
       " 'coconut-oil',\n",
       " 'coffee',\n",
       " 'copper',\n",
       " 'copra-cake',\n",
       " 'corn',\n",
       " 'cotton',\n",
       " 'cotton-oil',\n",
       " 'cpi',\n",
       " 'cpu',\n",
       " 'crude',\n",
       " 'dfl',\n",
       " 'dlr',\n",
       " 'dmk',\n",
       " 'earn',\n",
       " 'fuel',\n",
       " 'gas',\n",
       " 'gnp',\n",
       " 'gold',\n",
       " 'grain',\n",
       " 'groundnut',\n",
       " 'groundnut-oil',\n",
       " 'heat',\n",
       " 'hog',\n",
       " 'housing',\n",
       " 'income',\n",
       " 'instal-debt',\n",
       " 'interest',\n",
       " 'ipi',\n",
       " 'iron-steel',\n",
       " 'jet',\n",
       " 'jobs',\n",
       " 'l-cattle',\n",
       " 'lead',\n",
       " 'lei',\n",
       " 'lin-oil',\n",
       " 'livestock',\n",
       " 'lumber',\n",
       " 'meal-feed',\n",
       " 'money-fx',\n",
       " 'money-supply',\n",
       " 'naphtha',\n",
       " 'nat-gas',\n",
       " 'nickel',\n",
       " 'nkr',\n",
       " 'nzdlr',\n",
       " 'oat',\n",
       " 'oilseed',\n",
       " 'orange',\n",
       " 'palladium',\n",
       " 'palm-oil',\n",
       " 'palmkernel',\n",
       " 'pet-chem',\n",
       " 'platinum',\n",
       " 'potato',\n",
       " 'propane',\n",
       " 'rand',\n",
       " 'rape-oil',\n",
       " 'rapeseed',\n",
       " 'reserves',\n",
       " 'retail',\n",
       " 'rice',\n",
       " 'rubber',\n",
       " 'rye',\n",
       " 'ship',\n",
       " 'silver',\n",
       " 'sorghum',\n",
       " 'soy-meal',\n",
       " 'soy-oil',\n",
       " 'soybean',\n",
       " 'strategic-metal',\n",
       " 'sugar',\n",
       " 'sun-meal',\n",
       " 'sun-oil',\n",
       " 'sunseed',\n",
       " 'tea',\n",
       " 'tin',\n",
       " 'trade',\n",
       " 'veg-oil',\n",
       " 'wheat',\n",
       " 'wpi',\n",
       " 'yen',\n",
       " 'zinc']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.categories()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows the list of files that have the label \"corn\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/14832',\n",
       " 'test/14858',\n",
       " 'test/15033',\n",
       " 'test/15043',\n",
       " 'test/15106',\n",
       " 'test/15287',\n",
       " 'test/15341',\n",
       " 'test/15618',\n",
       " 'test/15648',\n",
       " 'test/15676',\n",
       " 'test/15686',\n",
       " 'test/15720',\n",
       " 'test/15845',\n",
       " 'test/15856',\n",
       " 'test/15860',\n",
       " 'test/15863',\n",
       " 'test/15871',\n",
       " 'test/15875',\n",
       " 'test/15877',\n",
       " 'test/15890',\n",
       " 'test/15904',\n",
       " 'test/15906',\n",
       " 'test/15910',\n",
       " 'test/15911',\n",
       " 'test/15917',\n",
       " 'test/15952',\n",
       " 'test/15999',\n",
       " 'test/16012',\n",
       " 'test/16071',\n",
       " 'test/16099',\n",
       " 'test/16147',\n",
       " 'test/16525',\n",
       " 'test/16624',\n",
       " 'test/16751',\n",
       " 'test/16765',\n",
       " 'test/17503',\n",
       " 'test/17509',\n",
       " 'test/17722',\n",
       " 'test/18035',\n",
       " 'test/18482',\n",
       " 'test/18614',\n",
       " 'test/18954',\n",
       " 'test/18973',\n",
       " 'test/19165',\n",
       " 'test/19721',\n",
       " 'test/19821',\n",
       " 'test/20018',\n",
       " 'test/20366',\n",
       " 'test/20637',\n",
       " 'test/20645',\n",
       " 'test/20649',\n",
       " 'test/20723',\n",
       " 'test/20763',\n",
       " 'test/21091',\n",
       " 'test/21243',\n",
       " 'test/21493',\n",
       " 'training/10120',\n",
       " 'training/10139',\n",
       " 'training/10172',\n",
       " 'training/10175',\n",
       " 'training/10319',\n",
       " 'training/10339',\n",
       " 'training/10487',\n",
       " 'training/10489',\n",
       " 'training/10519',\n",
       " 'training/10701',\n",
       " 'training/10882',\n",
       " 'training/10956',\n",
       " 'training/11012',\n",
       " 'training/11085',\n",
       " 'training/11091',\n",
       " 'training/11269',\n",
       " 'training/1131',\n",
       " 'training/11392',\n",
       " 'training/11436',\n",
       " 'training/11607',\n",
       " 'training/11612',\n",
       " 'training/11729',\n",
       " 'training/11739',\n",
       " 'training/11769',\n",
       " 'training/11885',\n",
       " 'training/11936',\n",
       " 'training/11939',\n",
       " 'training/11964',\n",
       " 'training/12002',\n",
       " 'training/12052',\n",
       " 'training/12055',\n",
       " 'training/1215',\n",
       " 'training/12160',\n",
       " 'training/12311',\n",
       " 'training/12323',\n",
       " 'training/12372',\n",
       " 'training/12417',\n",
       " 'training/12436',\n",
       " 'training/12500',\n",
       " 'training/12583',\n",
       " 'training/12587',\n",
       " 'training/1268',\n",
       " 'training/1273',\n",
       " 'training/12872',\n",
       " 'training/13173',\n",
       " 'training/13179',\n",
       " 'training/1369',\n",
       " 'training/1385',\n",
       " 'training/13852',\n",
       " 'training/13856',\n",
       " 'training/1395',\n",
       " 'training/1399',\n",
       " 'training/14483',\n",
       " 'training/1582',\n",
       " 'training/1652',\n",
       " 'training/1777',\n",
       " 'training/1843',\n",
       " 'training/193',\n",
       " 'training/1952',\n",
       " 'training/197',\n",
       " 'training/2044',\n",
       " 'training/2172',\n",
       " 'training/2183',\n",
       " 'training/2217',\n",
       " 'training/2264',\n",
       " 'training/235',\n",
       " 'training/2382',\n",
       " 'training/2436',\n",
       " 'training/2456',\n",
       " 'training/2595',\n",
       " 'training/2599',\n",
       " 'training/2617',\n",
       " 'training/2727',\n",
       " 'training/2741',\n",
       " 'training/2749',\n",
       " 'training/2777',\n",
       " 'training/2848',\n",
       " 'training/2913',\n",
       " 'training/2922',\n",
       " 'training/2947',\n",
       " 'training/3138',\n",
       " 'training/3191',\n",
       " 'training/327',\n",
       " 'training/3282',\n",
       " 'training/3299',\n",
       " 'training/3306',\n",
       " 'training/3330',\n",
       " 'training/3337',\n",
       " 'training/3358',\n",
       " 'training/3401',\n",
       " 'training/3429',\n",
       " 'training/3847',\n",
       " 'training/3855',\n",
       " 'training/3881',\n",
       " 'training/3949',\n",
       " 'training/395',\n",
       " 'training/3979',\n",
       " 'training/3981',\n",
       " 'training/4047',\n",
       " 'training/4133',\n",
       " 'training/4289',\n",
       " 'training/4296',\n",
       " 'training/4382',\n",
       " 'training/4490',\n",
       " 'training/4599',\n",
       " 'training/4825',\n",
       " 'training/4905',\n",
       " 'training/4939',\n",
       " 'training/4988',\n",
       " 'training/5',\n",
       " 'training/5003',\n",
       " 'training/501',\n",
       " 'training/5017',\n",
       " 'training/5033',\n",
       " 'training/5109',\n",
       " 'training/516',\n",
       " 'training/5185',\n",
       " 'training/5338',\n",
       " 'training/5467',\n",
       " 'training/5518',\n",
       " 'training/5531',\n",
       " 'training/5606',\n",
       " 'training/5610',\n",
       " 'training/5636',\n",
       " 'training/5637',\n",
       " 'training/57',\n",
       " 'training/5847',\n",
       " 'training/5933',\n",
       " 'training/6',\n",
       " 'training/6142',\n",
       " 'training/6221',\n",
       " 'training/6236',\n",
       " 'training/6239',\n",
       " 'training/6259',\n",
       " 'training/6269',\n",
       " 'training/6386',\n",
       " 'training/6585',\n",
       " 'training/6588',\n",
       " 'training/6735',\n",
       " 'training/6890',\n",
       " 'training/6897',\n",
       " 'training/694',\n",
       " 'training/7062',\n",
       " 'training/7205',\n",
       " 'training/7215',\n",
       " 'training/7336',\n",
       " 'training/7387',\n",
       " 'training/7389',\n",
       " 'training/7390',\n",
       " 'training/7395',\n",
       " 'training/7700',\n",
       " 'training/7792',\n",
       " 'training/7917',\n",
       " 'training/7934',\n",
       " 'training/7943',\n",
       " 'training/8004',\n",
       " 'training/8140',\n",
       " 'training/8161',\n",
       " 'training/8166',\n",
       " 'training/8257',\n",
       " 'training/8273',\n",
       " 'training/8400',\n",
       " 'training/8443',\n",
       " 'training/8446',\n",
       " 'training/8535',\n",
       " 'training/855',\n",
       " 'training/8759',\n",
       " 'training/8941',\n",
       " 'training/8983',\n",
       " 'training/8993',\n",
       " 'training/9058',\n",
       " 'training/9093',\n",
       " 'training/9094',\n",
       " 'training/934',\n",
       " 'training/9470',\n",
       " 'training/9521',\n",
       " 'training/9667',\n",
       " 'training/97',\n",
       " 'training/9865',\n",
       " 'training/9958',\n",
       " 'training/9989']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reuters.fileids(categories='corn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for three independent classifiers\n",
    "We will encode the labels of each document as a list of Boolean elements that indicate whether the document has a label or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corn_fileids = reuters.fileids(categories='corn')\n",
    "gold_fileids = reuters.fileids(categories='gold')\n",
    "grain_fileids = reuters.fileids(categories='grain')\n",
    "\n",
    "training_fileids = [f for f in reuters.fileids() if f[0:8]=='training']\n",
    "test_fileids = [f for f in reuters.fileids() if f[0:4]=='test']\n",
    "\n",
    "training_set = [(f, (f in corn_fileids, f in gold_fileids, f in grain_fileids)) for f in training_fileids]\n",
    "test_set = [(f, (f in corn_fileids, f in gold_fileids, f in grain_fileids)) for f in test_fileids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7769, 3019)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('test/14826', (False, False, False)),\n",
       " ('test/14828', (False, False, True)),\n",
       " ('test/14829', (False, False, False)),\n",
       " ('test/14832', (True, False, True)),\n",
       " ('test/14833', (False, False, False)),\n",
       " ('test/14839', (False, False, False)),\n",
       " ('test/14840', (False, False, False)),\n",
       " ('test/14841', (False, False, True)),\n",
       " ('test/14842', (False, True, False)),\n",
       " ('test/14843', (False, False, False))]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.', ',', 'the', 'to', 'of', 'in', 'and', 'said', 'a', 'mln']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "all_words = collections.Counter(w.lower() \\\n",
    "        for w in reuters.words(fileids=training_fileids))\n",
    "word_features = [w for (w, c) in all_words.most_common(500)]\n",
    "word_features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def document_features(fileid):\n",
    "    document_words = set([w.lower() for w in reuters.words(fileids=[fileid])])\n",
    "    features = dict()\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "training_features = [(document_features(f),t) for (f,t) in training_set]\n",
    "test_features = [(document_features(f),t) for (f,t) in test_set]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(corn) = True             True : False  =    182.5 : 1.0\n",
      "             contains(&) = True            False : True   =     69.0 : 1.0\n",
      "            contains(lt) = True            False : True   =     69.0 : 1.0\n",
      "             contains(>) = True            False : True   =     67.5 : 1.0\n",
      "             contains(;) = True            False : True   =     41.6 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier_corn = nltk.NaiveBayesClassifier.train((f, t[0]) for f, t in training_features)\n",
    "classifier_corn.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(gold) = True             True : False  =     94.9 : 1.0\n",
      "           contains(the) = False           False : True   =     22.0 : 1.0\n",
      "           contains(cts) = True            False : True   =     17.6 : 1.0\n",
      "            contains(vs) = True            False : True   =     16.7 : 1.0\n",
      "           contains(net) = True            False : True   =     15.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier_gold = nltk.NaiveBayesClassifier.train((f, t[1]) for f, t in training_features)\n",
    "classifier_gold.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "         contains(wheat) = True             True : False  =    233.1 : 1.0\n",
      "             contains(>) = True            False : True   =    166.6 : 1.0\n",
      "         contains(grain) = True             True : False  =    108.3 : 1.0\n",
      "          contains(corn) = True             True : False  =    106.3 : 1.0\n",
      "             contains(&) = True            False : True   =    102.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier_grain = nltk.NaiveBayesClassifier.train((f, t[2]) for f, t in training_features)\n",
    "classifier_grain.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8509440211990725"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier_corn, [(f, t[0]) for f, t in test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9744948658496191"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier_gold, [(f, t[1]) for f, t in test_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8373633653527658"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier_grain, [(f, t[2]) for f, t in test_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro-averaged Evaluation of F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(len(y_true)):\n",
    "        if y_true[i] == True:\n",
    "            if y_pred[i] == True:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "        elif y_pred[i] == True:\n",
    "            fp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    try:\n",
    "        r = tp/(tp+fn)\n",
    "    except:\n",
    "        r = 0.0\n",
    "    try:\n",
    "        p = tp/(tp+fp)\n",
    "    except:\n",
    "        p = 0.0\n",
    "    try:\n",
    "        f1 = 2*r*p/(r+p)\n",
    "    except:\n",
    "        f1 = 0.0\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False, True, True, True, True, True, False, False]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_corn = [classifier_corn.classify(f) for f, t in test_features]\n",
    "predictions_corn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, False, True, False, False, False, False, False, False]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_corn = [t[0] for f, t in test_features]\n",
    "true_corn[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_gold = [classifier_gold.classify(f) for f, t in test_features]\n",
    "predictions_grain = [classifier_grain.classify(f) for f, t in test_features]\n",
    "true_gold = [t[1] for f, t in test_features]\n",
    "true_grain = [t[2] for f, t in test_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corn f1: 0.18181818181818182\n",
      "gold f1: 0.3636363636363636\n",
      "grain f1: 0.3598435462842242\n",
      "Macro-average f1: 0.3018\n"
     ]
    }
   ],
   "source": [
    "totalf1 = 0\n",
    "thef1 = f1(true_corn, predictions_corn)\n",
    "print('corn f1:', thef1)\n",
    "totalf1 += thef1\n",
    "thef1 = f1(true_gold, predictions_gold)\n",
    "print('gold f1:', thef1)\n",
    "totalf1 += thef1\n",
    "thef1 = f1(true_grain, predictions_grain)\n",
    "print('grain f1:', thef1)\n",
    "totalf1 += thef1\n",
    "print(\"Macro-average f1: %1.4f\" % (totalf1/3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Micro-averaged Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def f1_micro(y_true, y_pred):\n",
    "    \"\"\"y_true[i] is the list of true annotations for label i\n",
    "       y_pred[i] is the list of predictions for label i\"\"\"\n",
    "    assert len(y_true) == len(y_pred)\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for label in range(3):\n",
    "        for i in range(len(y_true[label])):\n",
    "            if y_true[label][i] == True:\n",
    "                if y_pred[label][i] == True:\n",
    "                    tp += 1\n",
    "                else:\n",
    "                    fn += 1\n",
    "            elif y_pred[label][i] == True:\n",
    "                fp += 1\n",
    "            else:\n",
    "                tn += 1\n",
    "    try:\n",
    "        r = tp/(tp+fn)\n",
    "    except:\n",
    "        r = 0.0\n",
    "    try:\n",
    "        p = tp/(tp+fp)\n",
    "    except:\n",
    "        p = 0.0\n",
    "    try:\n",
    "        f1 = 2*r*p/(r+p)\n",
    "    except:\n",
    "        f1 = 0.0\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-average f1: 0.2921\n"
     ]
    }
   ],
   "source": [
    "print(\"Micro-average f1: %1.4f\" % f1_micro((true_corn, true_gold, true_grain),\n",
    "                                           (predictions_corn, predictions_gold, predictions_grain)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
